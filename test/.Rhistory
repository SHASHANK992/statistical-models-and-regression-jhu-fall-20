ones <- rep(1, n)
x1 <- df[,2]; x2 <- df[,3]
X <- cbind(ones, x1, x2)
### part (a)
### part (b)
### part (c)
### part (d)
beta_hat_calc <- function(X, y) {
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% y
return(beta_hat)
}
H_calc <- function(X) {
H <- X %*% solve(t(X) %*% X) %*% t(X)
return(H)
}
y_hat_calc <- function(H, y) {
y_hat <- H %*% y
return(y_hat)
}
e_calc <- function(y, y_hat) {
e <- y - y_hat
return(e)
}
X_d <- X[,c(1,3)]
beta_hat_d <- beta_hat_calc(X = X_d, y = y)
beta_hat_d
H_d <- H_calc(X = X_d)
y_hat_d <- y_hat_calc(H = H_d, y = y)
e_d <- e_calc(y = y, y_hat = y_hat_d)
e_d
e_d[8]
e_d[8]
cars
iris
x = iris$Species
y = iris$Sepal.Length
x = iris$Species
y = iris$Sepal.Length
lm(y ~ factor(x))
lm(y ~ x)
x = iris$Species
y = iris$Sepal.Length
lm(y ~ x)
x1 = ifelse(iris$Species == "versicolor", 5, -10)
x1
lm(y ~ x)
x2 = ifelse(iris$Species == "virginica", 7, -2)
fit1 <- lm(y ~ x)
fit2 <- lm(y ~ x1 + x2)
x1 = ifelse(iris$Species == "versicolor", 5, -10)
x2 = ifelse(iris$Species == "virginica", 7, -2)
fit2 <- lm(y ~ x1 + x2)
fit1
fit2
fit1$fitted.values
fit1$fitted.values == fit2$fitted.values
X_d <- X[,c(1,3)]
beta_hat_d <- beta_hat_calc(X = X_d, y = y)
H_d <- H_calc(X = X_d)
y_hat_d <- y_hat_calc(H = H_d, y = y)
e_d <- e_calc(y = y, y_hat = y_hat_d)
### Problem 3
df <- data.frame(
y=c(7,8,5,4,2,10,9,10,8,8),
x1=c(9,6,10,8,5,7,6,5,5,4),
x2=rep(c(1,-1), each=5)
)
y <- df[,1]
n <- nrow(df)
ones <- rep(1, n)
x1 <- df[,2]; x2 <- df[,3]
X <- cbind(ones, x1, x2)
### part (d)
beta_hat_calc <- function(X, y) {
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% y
return(beta_hat)
}
H_calc <- function(X) {
H <- X %*% solve(t(X) %*% X) %*% t(X)
return(H)
}
y_hat_calc <- function(H, y) {
y_hat <- H %*% y
return(y_hat)
}
e_calc <- function(y, y_hat) {
e <- y - y_hat
return(e)
}
X_d <- X[,c(1,3)]
beta_hat_d <- beta_hat_calc(X = X_d, y = y)
H_d <- H_calc(X = X_d)
y_hat_d <- y_hat_calc(H = H_d, y = y)
e_d <- e_calc(y = y, y_hat = y_hat_d)
e_d[8]
beta_hat_d
X
X <- cbind(ones, x1, x2, x1*x2)
X
beta_hat
beta_hat <- beta_hat_calc(X = X, y = y)
beta_hat
beta_hat_full <- beta_hat_calc(X = X, y = y)
X_red <- cbind(ones, x1)
X_red <- cbind(ones, x1)
beta_hat_full <- beta_hat_calc(X = X, y = y)
beta_hat_red <- beta_hat_calc(X = X_red, y = y)
SS_R_calc <- function(beta_hat, X, y) {
n <- length(y)
SS_R <- (t(beta_hat) %*% t(X) %*% y) - ((sum(y)^2) / n)
return(SS_R)
}
SS_R_full <- SS_R_calc(beta_hat = beta_hat, X = X, y = y)
SS_R_red <- SS_R_calc(beta_hat = beta_hat_red, X = X_red, y = y)
SS_R_full
SS_R_red
SS_Res_calc <- function(y, beta_hat, X) {
SS_Res <- (t(y) %*% y) - (t(beta_hat) %*% t(X) %*% y)
return(SS_Res)
}
SS_Res_full <- SS_Res_calc(y = y, beta_hat = beta_hat, X = X)
k <- 3
MS_Res <- SS_Res_full / k
F_0 <- ((SS_R_full - SS_R_red) / 2) / MS_Res
F_0
alpha <- 0.05
qf(p = (1 - alpha), df1 = k, df2 = (n - k - 1))
pf(q = F_a, df1 = k, df2 = (n - k - 1), lower.tail = FALSE)
pf(q = F_0, df1 = k, df2 = (n - k - 1), lower.tail = FALSE)
################################# Remove
m1 <- lm(y ~ x1*x2)
m2 <- lm(y ~ x1)
anova(m1, m2)
m1
beta_hat
m2
beta_hat_red
anova(m1, m2)
F_0
F_0 * 2
k
r <- 2
F_0 <- ((SS_R_full - SS_R_red) / r) / MS_Res
F_0
k <- 3; p <- k + 1
r <- 2
MS_Res <- SS_Res_full / (n - p)
SS_R_full <- SS_R_calc(beta_hat = beta_hat, X = X, y = y)
SS_R_red <- SS_R_calc(beta_hat = beta_hat_red, X = X_red, y = y)
F_0 <- ((SS_R_full - SS_R_red) / r) / MS_Res
F_0
alpha <- 0.05
qf(p = (1 - alpha), df1 = k, df2 = (n - k - 1))
pf(q = F_0, df1 = k, df2 = (n - k - 1), lower.tail = FALSE)
anova(m1, m2)
pf(q = F_0, df1 = r, df2 = (n - k - 1), lower.tail = FALSE)
n-p
F_0
pf(q = F_0, df1 = r, df2 = (n - k - 1), lower.tail = FALSE)
anova(m1,m2)
beta_hat
### part (b)
2 * beta_hat[3] + 10 * beta_hat[4]
?pnorm
qnorm(alpha/2)
qnorm(alpha/2, lower.tail = FALSE)
z_value <- qnorm(alpha/2, lower.tail = FALSE)
x_01 <- c(1, 5, 1, 5)
x_02 <- c(1, 5, -1, -5)
X
CI_bound <- z_value * sqrt(t(x_01 - x_02) %*%
solve(t(X) %*% X) %*%
(x_01 - x_02))
CI_bound
y_hat_01 <- x_01 %*% beta_hat
y_hat_02 <- x_02 %*% beta_hat
(y_hat_01 - y_hat_02) + CI_bound
(y_hat_01 - y_hat_02) - CI_bound
y_hat_01 - y_hat_02
y_hat_01
y_hat_02
y_hat_01 <- t(x_01) %*% beta_hat
y_hat_01
y_hat_02 <- t(x_02) %*% beta_hat
y_hat_02
sigma_squared <- 2
CI_bound <- z_value * sqrt(sigma_squared * t(x_01 - x_02) %*%
solve(t(X) %*% X) %*%
(x_01 - x_02))
CI_bound
CI_bound <- z_value * sqrt(sigma_squared * t(x_01 - x_02) %*%
solve(t(X) %*% X) %*%
(x_01 - x_02))
CI_bound
z_value <- qnorm(alpha/2, lower.tail = FALSE)
x_01 <- c(1, 5, 1, 5)
x_02 <- c(1, 5, -1, -5)
y_hat_01 <- t(x_01) %*% beta_hat
y_hat_02 <- t(x_02) %*% beta_hat
sigma_squared <- 2
CI_bound <- z_value * sqrt(sigma_squared * t(x_01 - x_02) %*%
solve(t(X) %*% X) %*%
(x_01 - x_02))
(y_hat_01 - y_hat_02) + CI_bound
(y_hat_01 - y_hat_02) - CI_bound
PI_bound <- z_value * sqrt(sigma_squared *
(2 +
t(x_01 - x_02) %*%
solve(t(X) %*% X) %*%
(x_01 - x_02)))
(y_hat_01 - y_hat_02) + PI_bound
(y_hat_01 - y_hat_02) - PI_bound
PI_bound
(y_hat_01 - y_hat_02) - PI_bound
(y_hat_01 - y_hat_02) + PI_bound
y_hat_01 - y_hat_02
### part (d)
X_d <- X[,c(1,3)]
beta_hat_d <- beta_hat_calc(X = X_d, y = y)
H_d <- H_calc(X = X_d)
y_hat_d <- y_hat_calc(H = H_d, y = y)
e_d <- e_calc(y = y, y_hat = y_hat_d)
e_d[8]
beta_hat_d
y_hat_d
y
diag(n)
diag(n) - H_d
sigma_squared * (diag(n) - H_d)
residual_variance <- sigma_squared * (diag(n) - H_d)
residual_variance[8,8]
N <- 1e3
# Reference: https://stats.stackexchange.com/questions/70855/generating-random-variables-from-a-mixture-of-normal-distributions
set.seed(1): u_sample <- runif(n = N)
# Reference: https://stats.stackexchange.com/questions/70855/generating-random-variables-from-a-mixture-of-normal-distributions
set.seed(1); u_sample <- runif(n = N)
x1 <- rep(NA, N)
x1 <- sapply(1:N, function(x) {
if (u_sample[x] > 0.6) {
return(rnorm(n = 1, mean = 0, sd = 1))
} else {
return(rnorm(n = 1, mean = 2.5, sd = 2))
}
})
plot(density(x1))
plot(density(u_sample))
range(u_sample)
# Reference: https://stats.stackexchange.com/questions/70855/generating-random-variables-from-a-mixture-of-normal-distributions
set.seed(1); u_sample <- runif(n = N)
set.seed(1)
x1 <- sapply(1:N, function(x) {
if (u_sample[x] > 0.6) {
return(rnorm(n = 1, mean = 0, sd = 1))
} else {
return(rnorm(n = 1, mean = 2.5, sd = 2))
}
})
x2 <- sapply(1:N, function(x) {
if (u_sample[x] > 0.1) {
return(rnorm(n = 1, mean = 1, sd = 2))
} else {
return(rnorm(n = 1, mean = 3, sd = 5))
}
})
x1x2 <- x1*x2
c(1,2,3) * c(4,5,6)
y <- 2 * x1 + 3 * x2 + 0.5 * x1x2
y <- 2 * x1 + 3 * x2 + 0.5 * x1x2 + rnorm(n = N, mean = 0, sd = 1)
y
plot(density(y))
# Generate data
N <- 1e3
# Reference: https://stats.stackexchange.com/questions/70855/generating-random-variables-from-a-mixture-of-normal-distributions
set.seed(1); u_sample <- runif(n = N)
set.seed(1)
x1 <- sapply(1:N, function(x) {
if (u_sample[x] > 0.6) {
return(rnorm(n = 1, mean = 0, sd = 1))
} else {
return(rnorm(n = 1, mean = 2.5, sd = 2))
}
})
set.seed(1)
x2 <- sapply(1:N, function(x) {
if (u_sample[x] > 0.1) {
return(rnorm(n = 1, mean = 1, sd = 2))
} else {
return(rnorm(n = 1, mean = 3, sd = 5))
}
})
x1x2 <- x1*x2
y <- 1.5 + 2 * x1 + 3 * x2 + 0.5 * x1x2 + rnorm(n = N, mean = 0, sd = 1)
plot(density(y))
plot(density(x1))
plot(density(y))
par(mfrow=c(2,2))
plot(density(y));plot(density(x1));plot(density(x2));plot(density(x1x2))
# Generate data
N <- 1e3
set.seed(1); x1 <- rnorm(n = N, mean = 0, sd = 1)
set.seed(1); x2 <- rnorm(n = N, mean = 2.5, sd = 1.5)
x1x2 <- x1*x2
y <- 1.5 + 2 * x1 + 3 * x2 + 0.5 * x1x2 + rnorm(n = N, mean = 0, sd = 1)
par(mfrow=c(2,2))
plot(density(y));plot(density(x1));plot(density(x2));plot(density(x1x2))
library(leaps)
df <- cbind(y, x1, x2, x1x2)
best <- regsubsets(x = y~., data = df, nvmax = 3)
df <- as.data.frame(cbind(y, x1, x2, x1x2))
best <- regsubsets(x = y~., data = df, nvmax = 3)
best <- regsubsets(x = y~., data = df, nvmax = 2)
head(df)
best <- regsubsets(x = y~., data = df, nvmax = 3)
res.sum <- summary(best)
res.sum
best <- regsubsets(x = y~., data = df, nvmax = 4)
res.sum <- summary(best)
res.sum
best <- regsubsets(x = y~., data = df, nvmax = 3)
res.sum <- summary(best)
res.sum
p.m <- 2:4
aic <- n * log(res.sum$rss / n) + 2 * p.m
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic)
)
aic <- n * log(res.sum$rss / N) + 2 * p.m
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic)
)
aic <- N * log(res.sum$rss / N) + 2 * p.m
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic)
)
best
res.sum
best <- regsubsets(x = y~., data = df, nvmax = 3)
dim(df)
df <- as.data.frame(as.matrix(cbind(y, x1, x2, x1x2)))
best <- regsubsets(x = y~., data = df, nvmax = 3)
df <- as.matrix(cbind(y, x1, x2, x1x2))
best <- regsubsets(x = y~., data = df, nvmax = 3)
df <- as.data.frame(cbind(y, x1, x2, x1x2))
best <- regsubsets(x = y~., data = df, nvmax = 3)
leaps.setup
# full model
df <- as.data.frame(cbind(y, x1, x2, x1x2))
full_model <- lm(formula = y~., data = df)
summary(ffull_model)
summary(full_model)
# Generate data
N <- 1e3
# Reference: https://stats.stackexchange.com/questions/70855/generating-random-variables-from-a-mixture-of-normal-distributions
set.seed(1); u_sample <- runif(n = N)
set.seed(1)
x1 <- sapply(1:N, function(x) {
if (u_sample[x] > 0.6) {
return(rnorm(n = 1, mean = 0, sd = 1))
} else {
return(rnorm(n = 1, mean = 2.5, sd = 2))
}
})
set.seed(1)
x2 <- sapply(1:N, function(x) {
if (u_sample[x] > 0.1) {
return(rnorm(n = 1, mean = 1, sd = 2))
} else {
return(rnorm(n = 1, mean = 3, sd = 5))
}
})
x1x2 <- x1*x2
y <- 1.5 + 2 * x1 + 3 * x2 + 0.5 * x1x2 + rnorm(n = N, mean = 0, sd = 1)
par(mfrow=c(2,2))
plot(density(y));plot(density(x1));plot(density(x2));plot(density(x1x2))
# full model
df <- as.data.frame(cbind(y, x1, x2, x1x2))
full_model <- lm(formula = y~., data = df)
summary(full_model)
# all possible regressors
best <- regsubsets(x = y~., data = df, nvmax = 3)
res.sum <- summary(best)
res.sum
p.m <- 2:4
aic <- N * log(res.sum$rss / N) + 2 * p.m
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic)
)
data.frame(
r2 = which.max(res.sum$rsq),
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic)
)
data.frame(
R2 = which.max(res.sum$rsq),
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic)
)
?regsubsets
N - p.m
MS_Res <- res.sum$rss / (N - p.m)
MS_Res
res.sum$rss
res.sum$rss[1] / 998
res.sum$rss[2] / 997
data.frame(
R2 = which.max(res.sum$rsq),
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic),
MSRes = which.min(MS_Res)
)
summary(full_model)
best
best$call
best$nn
?fowrad
?forward
?backward
?step
?stepwise
intercept_only <- lm(y~1, data = df)
# forward selection
forward <- MASS::stepAIC(intercept_only,
scope = list(upper=full_model, lower=intercept_only),
direction = c('forward'))
# backward elimination
backward <- MASS::stepAIC(full_model,
# scope = list(upper=full_model, lower=intercept_only),
direction = c('backward'))
# stepwise regression
stepwise <- MASS::stepAIC(intercept_only,
scope = list(upper=full_model, lower=intercept_only),
direction = c('both'))
?regsubsets
res.sum
data.frame(
R2 = which.max(res.sum$rsq),
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic),
MSRes = which.min(MS_Res)
)
data.frame(
R2 = which.max(res.sum$rsq), res.sum$rsq[which.max(res.sum$rsq)],
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic),
AIC = which.min(aic),
MSRes = which.min(MS_Res)
)
data.frame(
R2 = res.sum$rsq[3],
Adj.R2 = res.sum$adjr2[3],
CP = res.sum$cp[3],
BIC = res.sum$bic[3],
AIC = aic[3],
MSRes = MS_Res[3]
)
data.frame(
R2 = round(res.sum$rsq[3],4),
Adj.R2 = round(res.sum$adjr2[3],4),
CP = round(res.sum$cp[3],4),
BIC = round(res.sum$bic[3],4),
AIC = round(aic[3],4),
MSRes = round(MS_Res[3],4)
)
res.sum$bic
forward
# forward selection
forward <- MASS::stepAIC(intercept_only,
scope = list(upper=full_model, lower=intercept_only),
direction = c('forward'))
?MASS::stepAIC
?MASS::step
# forward selection
forward <- MASS::stepAIC(intercept_only,
scope = list(upper=full_model, lower=intercept_only),
direction = c('forward'))
# backward elimination
backward <- MASS::stepAIC(full_model,
# scope = list(upper=full_model, lower=intercept_only),
direction = c('backward'))
# stepwise regression
stepwise <- MASS::stepAIC(intercept_only,
scope = list(upper=full_model, lower=intercept_only),
direction = c('both'))
full_model
summary(full_model)
par(mfrow=c(2,2))
plot(density(y));plot(density(x1));plot(density(x2));plot(density(x1x2))
plot(density(y), main = 'Density Plot of y')
plot(density(x1), main = 'Density Plot of x1')
plot(density(x2), main = 'Density Plot of x2')
plot(density(x1x2), main = 'Density Plot of x1x2')
